/*

active-learning-scala: Active Learning library for Scala
Copyright (c) 2014 Davi Pereira dos Santos

   This program is free software: you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation, either version 3 of the License, or
   (at your option) any later version.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

package clean.tex

import java.io.{File, FileWriter, OutputStream, PrintStream}

import clean.lib.{FilterTrait, Log, Rank}
import clus.Clus
import ml.Pattern
import ml.classifiers.{SVMLibRBF, Learner, NinteraELM, RF}
import ml.models.ELMModel
import org.apache.commons.math3.stat.correlation.SpearmansCorrelation
import util.{Datasets, Stat}
import weka.attributeSelection.GreedyStepwise
import weka.core.DenseInstance
import weka.core.converters.ArffSaver

import scala.collection.mutable
import scala.util.Random

trait MetaTrait extends FilterTrait with Rank with Log {
  def clusSettings(natts: Int, targets: Int, seed: Int, arqtr: String, arqts: String) = {
    val ultimoDesc = natts + 1
    val primeiroTarget = ultimoDesc + 1
    val ultimoTarget = primeiroTarget + targets - 1
    Seq(
      "[Data]",
      s"File = $arqtr.arff",
      s"TestSet = $arqts.arff",
      "",
      "[General]",
      s"RandomSeed = $seed",
      "",
      "[Attributes]",
      s"Descriptive = 2-$ultimoDesc",
      s"Target = $primeiroTarget-$ultimoTarget",
      s"Clustering = $primeiroTarget-$ultimoTarget",
      "Weights = 1",
      "",
      "[Tree]",
      "Heuristic = VarianceReduction",
      "FTest = 1",
      //      "PruningMethod = C4.5",//quebra
      //            "PruningMethod = M5Multi",//ajuda
      //      "M5PruningMult = 1", //ajuda mais
      "",
      "[Ensemble]",
      "Iterations = 500",
      "EnsembleMethod = Bagging", //Bagging, RForest, RSubspaces, BagSubspaces só funfou bagging
      "",
      "[Output]",
      "WritePredictions = {Test}"
    ).mkString("\n")
  }


  def arff(strats: String, exemplos: Seq[(Seq[(String, String, String)], String)], print: Boolean = false, context: String, rank: Boolean) = {
    lazy val labels = exemplos.map(x => x._2).distinct.sorted
    lazy val classAtt = "@attribute class {" + labels.map(x => "\"" + x + "\"").mkString(",") + "}"
    val attsNameType = exemplos.head._1 map { case (no, va, ty) => s"$no $ty" }
    val header = List(s"@relation autogeneratedby$context") ++ (attsNameType map (nt => s"@attribute $nt")) ++ (if (rank) List() else List(classAtt))
    val data = exemplos.map(x => "\"" + x._1.head._2 + "\"," + x._1.tail.map(_._2).mkString(",") + (if (rank) "" else s"," + "\"" + x._2 + "\""))
    if (print) {
      //      println("labels: " + labels.mkString(" "))
      //      println(s"#classes: ${labels.size}")
      println(s"#atributos: ${exemplos.head._1.size}")
      println(s"#exemplos: ${exemplos.size}")
    }
    Seq("%" + strats) ++ header ++ Seq("@data") ++ data
  }

  def grava(arq: String, linhas: Seq[String], print: Boolean = false): Unit = {
    val fw = new FileWriter(arq)
    linhas foreach (x => fw.write(s"$x\n"))
    fw.close()
    if (print) linhas foreach println
  }

  def instances2file(patterns: Vector[Pattern], arq: String) {
    val as = new ArffSaver()
    as.setInstances(Datasets.patterns2instances(patterns))
    as.setFile(new File(arq + ".arff"))
    as.writeBatch()
  }

  val originalStream = System.out
  val dummyStream = new PrintStream(new OutputStream() {
    def write(b: Int) {}
  })

  /*
    val filter = new AttributeSelection()
  val eval = new WrapperSubsetEval()
  eval.setClassifier(cla)
  eval.setFolds(foldsInterno)
  eval.setSeed(fold * run)
  val search = new GreedyStepwise()
  search.setSearchBackwards(true)
  //        search.setThreshold(0.01) acho que não precisa setar pelo que li num forum http://forums.pentaho.com/showthread.php?90966-WEKA-attribute-selection
  search.setGenerateRanking(true)
  search.setNumToSelect(nfeaturesW)
  search.setNumExecutionSlots(8)
  filter.setEvaluator(eval)
  filter.setSearch(search)
  filter.setInputFormat(tr0.head.dataset())
  val tr = Datasets.applyFilter(filter)(tr0) //instances2patterns(Datasets.pcaWeka(Datasets.patterns2instances(tr1), 15)).toVector
  val ts = Datasets.applyFilter(filter)(ts0)

   */
  def cv(attsel: Boolean, patterns: Vector[Pattern], leas: Vector[Pattern] => Vector[Learner], rank: Boolean, rs: Int, ks: Int) = {
    if (attsel) ???
    (1 to rs).par map { run =>
      val shuffled = new Random(run).shuffle(patterns)
      val bags = shuffled.groupBy(_.base).values.toVector

      Datasets.kfoldCV2(bags, ks, parallel = true) { (trbags, tsbags, fold, minSize) =>
        val seed = run * 100 + fold
        val tr0 = trbags.flatten.toVector
        val ts0 = tsbags.flatten.toVector
        val (tr, ts) = if (rank) tr0 -> ts0
        else {
          val f = Datasets.removeBagFilter(tr0)
          Datasets.applyFilter(f)(tr0) -> Datasets.applyFilter(f)(ts0)
        }

        lazy val (trf, tsf) = replacemissingNom2binRmuselessZscore(tr, ts)
        //pega apenas um ex. por base (um que tiver label mais frequente)
        lazy val tr_trfSemParecidos = Seq(tr, trf) map { trx =>
          if (!rank) tr0.zip(trx).groupBy(_._1.base).map { case (k, lists) =>
            val (_, list) = lists.unzip
            val moda = list.groupBy(_.label).toList.sortBy(_._2.size).last._1
            val attsMedio = media(list.map(_.array))
            val pa = list.head
            val id = pa.id
            val inst = new DenseInstance(1d, attsMedio :+ moda)
            inst.setDataset(pa.dataset)
            Pattern(id, inst, missed = false, pa.parent)
          }.toSeq
          else tr0.zip(trx).groupBy(_._1.base).map { case (k, lists) =>
            val (_, list) = lists.unzip
            val rankMedio = media(list.map(_.targets))
            val descMedio = media(list.map(_.array))
            val pa = list.head
            val id = pa.id
            val inst = new DenseInstance(1d, pa.toDoubleArray.take(1) ++ descMedio ++ rankMedio)
            inst.setDataset(pa.dataset)
            Pattern(id, inst, missed = false, pa.parent)
          }.toSeq
        }
        lazy val (trSemParecidos1, trfSemParecidos1) = tr_trfSemParecidos.head.toVector -> tr_trfSemParecidos(1).toVector

        if (leas(tr).isEmpty) {
          //ELM
          val l = NinteraELM(seed)
          val m0 = l.batchBuild(trfSemParecidos1).asInstanceOf[ELMModel] //selecionar com todos foi pior (e bem mais lento) que tirando similares 38.6 < 44.0
          val L = l.LForMeta(m0, LOO = false)
          println(s"${L} <- L")
          val mfull0 = l.batchBuild(trf).asInstanceOf[ELMModel] //treinar com todos foi melhor que tirando similares 44.0 > 42.5
          val mfull = l.fullBuildForMeta(L, mfull0)
          val ELMRanks = tsf.toVector map { p => mfull.output(p) }

          //clus; seed tb serve pra situar run e fold durante paralelização
          val arqtr = s"/run/shm/tr$seed"
          val arqts = s"/run/shm/ts$seed"
          instances2file(trSemParecidos1, arqtr) //sem redundantes: 48/54; com todos 43/44
          instances2file(ts, arqts)
          val f = new FileWriter(s"/run/shm/clus$seed.s")
          f.write(clusSettings(patterns.head.nattributes, patterns.head.nclasses, seed, arqtr, arqts))
          f.close()

          System.setOut(dummyStream)
          Clus.main(Array("-forest", "-silent", s"/run/shm/clus$seed"))
          System.setOut(originalStream)

          val clusPredictionsARFF = Datasets.arff(s"/run/shm/clus$seed.test.pred.arff", dedup = false, rmuseless = false) match {
            case Right(x) => x
            case Left(m) => error(s"${m} <- m")
          }

          val clusOrigRanks_clusPrunRanks = Vector("Original-p") map { str =>
            //          val clusOrigRanks_clusPrunRanks = Vector("Original-p", "Pruned-p") map { str =>
            clusPredictionsARFF.map { pa =>
              pa.array.zipWithIndex.flatMap { case (v, i) => if (pa.attribute(i).name.startsWith(str)) Some(v) else None }
            }
          }

          val trtargets = tr.toSeq map (_.targets)
          val tstargets = ts.toSeq map (_.targets)

          //Default
          val rankMedio = media(trtargets)
          val defaultRanks = ts map (_ => rankMedio)

          clusOrigRanks_clusPrunRanks ++ Vector(ELMRanks, defaultRanks) map { ranks =>
            val spearsTrTs = Seq(trtargets, tstargets).map { txtargets =>
              ranks.zip(txtargets) map { case (ranking, targets) =>
                try {
                  val res = new SpearmansCorrelation().correlation(ranking, targets)
                  if (res.isNaN) 0d
                  //justQuit("\n\n\nNaN no Spear:" + ranking.toList + " " + targets.toList + "\n\n\n")
                  else res
                } catch {
                  case x: Throwable => error("\n " + ranking.toList + "\n " + rankMedio.toList + "\n " + targets.toList + " \n" + x)
                }
              }
            }
            (Vector(Stat.media_desvioPadrao(spearsTrTs.head)._1, Stat.media_desvioPadrao(spearsTrTs(1))._1), List[String](), Vector(List[Double](), List[Double](), List[Double](), List[Double]()))
          }

        } else {
          //attsel
          val labels = tr.map(_.nominalLabel).distinct
          val trattsel = tr //trSemParecidos1 <- fiasco
          val trfattsel = trf //trfSemParecidos1 <- fiasco
          val tsattsel = ts
          val tsfattsel = tsf
          val trfSemParecidos1attsel = trfSemParecidos1

          leas(trattsel) map { le =>
            val (trtestbags, tstestbags, m) = if (le.querFiltro) {
              val mo = le match {
                case NinteraELM(_, _) =>
                  val l = NinteraELM(seed)
                  //pega apenas a média dos exs. de cada base
                  val m0 = l.batchBuild(trfSemParecidos1attsel).asInstanceOf[ELMModel] //foi melhor filtrar: 41,7 > 36,9
                val L = l.LForMeta(m0, LOO = true)
                  println(s"${L} <- L")
                  val m = l.batchBuild(trfattsel).asInstanceOf[ELMModel] //41,7 > 39,3
                  l.fullBuildForMeta(L, m)
                case SVMLibRBF(_) => SVMLibRBF(seed).build(trfattsel) //SVM fica um pouco mais rápida sem exemplos redundantes, mas 42,5 > 33,1
                case _ => le.build(trfattsel)
              }
              (trfattsel.groupBy(x => x.vector), tsfattsel.groupBy(x => x.vector), mo)
            } else {
              val mo = le match {
                case RF(_, n, _, _) => RF(seed, n).build(trattsel)
                case _ => le.build(trattsel)
              }
              (trattsel.groupBy(x => x.vector), tsattsel.groupBy(x => x.vector), mo)
            }
            var exsPorClasse: mutable.Map[String, Int] = null
            var acertosPorClasse: mutable.Map[String, Int] = null
            val exsPorClasseTr = mutable.Map[String, Int](labels.map(_ -> 0): _*)
            val acertosPorClasseTr = mutable.Map[String, Int](labels.map(_ -> 0): _*)
            val fim = Vector(trtestbags, tstestbags) map { bags =>
              val resbags = (bags.map(_._2) map { xbag =>
                val metaclass = xbag.head.nominalLabel
                val lab = m.predict(xbag.head).toInt
                val re = xbag.map(_.label).contains(lab)
                if (re && acertosPorClasse != null) acertosPorClasse(metaclass) += 1
                if (re && acertosPorClasse == null) acertosPorClasseTr(metaclass) += 1
                if (exsPorClasse != null) exsPorClasse(metaclass) += 1
                if (exsPorClasse == null) exsPorClasseTr(metaclass) += 1
                re
              }).count(_ == true) / bags.size.toDouble
              //somente cjt de teste vai pro histograma
              if (acertosPorClasse == null) {
                acertosPorClasse = mutable.Map[String, Int](labels.map(_ -> 0): _*)
                exsPorClasse = mutable.Map[String, Int](labels.map(_ -> 0): _*)
              }
              resbags
            }
            (fim, acertosPorClasseTr.toList.map(_._1).sorted, Vector(acertosPorClasseTr.toList.sortBy(_._1).map(_._2.toDouble), exsPorClasseTr.toList.sortBy(_._1).map(_._2.toDouble), acertosPorClasse.toList.sortBy(_._1).map(_._2.toDouble), exsPorClasse.toList.sortBy(_._1).map(_._2.toDouble)))
          }
        }
      }
    }
  }

  def zipper(map1: Map[String, Int], map2: Map[String, Int]) = {
    for (key <- map1.keys ++ map2.keys)
      yield (key, map1.getOrElse(key, 0), map2.getOrElse(key, 0))
  }
}
/*

active-learning-scala: Active Learning library for Scala
Copyright (c) 2014 Davi Pereira dos Santos

   This program is free software: you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation, either version 3 of the License, or
   (at your option) any later version.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

package clean.tex

import java.io.{File, FileWriter}

import clean.lib.{Log, Rank, FilterTrait}
import clus.Clus
import ml.Pattern
import ml.classifiers.{NinteraELM, Learner}
import ml.models.ELMModel
import org.apache.commons.math3.stat.correlation.SpearmansCorrelation
import util.{Stat, Datasets}
import weka.core.converters.ArffSaver
import weka.filters.Filter

import scala.util.Random

trait MetaTrait extends FilterTrait with Rank with Log {
  def clusSettings(natts: Int, targets: Int, seed: Int, arqtr: String, arqts: String) = {
    val ultimoDesc = natts
    val primeiroTarget = ultimoDesc + 1
    val ultimoTarget = primeiroTarget + targets - 1
    Seq(
      "[Data]",
      s"File = $arqtr.arff",
      s"TestSet = $arqts.arff",
      "",
      "[General]",
      s"RandomSeed = $seed",
      "",
      "[Attributes]",
      s"Descriptive = 2-$ultimoDesc",
      s"Target = $primeiroTarget-$ultimoTarget",
      s"Clustering = $primeiroTarget-$ultimoTarget",
      "Weights = 1",
      "",
      "[Tree]",
      "Heuristic = VarianceReduction",
      "FTest = 1",
      "PruningMethod = M5Multi",
      "M5PruningMult = 1",
      "",
      "[Output]",
      "WritePredictions = {Test}"
    ).mkString("\n")
  }


  def arff(strats: String, exemplos: Seq[(Seq[(String, String, String)], String)], print: Boolean = false, context: String, rank: Boolean) = {
    lazy val labels = exemplos.map(x => x._2).distinct.sorted
    lazy val classAtt = "@attribute class {" + labels.map(x => "\"" + x + "\"").mkString(",") + "}"
    val attsNameType = exemplos.head._1 map { case (no, va, ty) => s"$no $ty" }
    val header = List(s"@relation autogeneratedby$context") ++ (attsNameType map (nt => s"@attribute $nt")) ++ (if (rank) List() else List(classAtt))
    val data = exemplos.map(x => "\"" + x._1.head._2 + "\"," + x._1.tail.map(_._2).mkString(",") + (if (rank) "" else s"," + "\"" + x._2 + "\""))
    if (print) {
      //      println("labels: " + labels.mkString(" "))
      //      println(s"#classes: ${labels.size}")
      println(s"#atributos: ${exemplos.head._1.size}")
      println(s"#exemplos: ${exemplos.size}")
    }
    Seq("%" + strats) ++ header ++ Seq("@data") ++ data
  }

  def grava(arq: String, linhas: Seq[String], print: Boolean = false): Unit = {
    val fw = new FileWriter(arq)
    linhas foreach (x => fw.write(s"$x\n"))
    fw.close()
    if (print) linhas foreach println
  }

  def instances2file(patterns: Vector[Pattern], arq: String) {
    val as = new ArffSaver()
    as.setInstances(Datasets.patterns2instances(patterns))
    as.setFile(new File(arq + ".arff"))
    as.writeBatch()
  }

  def cv(patterns: Vector[Pattern], leas: Vector[Pattern] => Vector[Learner], rank: Boolean, rs: Int, ks: Int) = {

    (1 to rs).par map { run =>
      val shuffled = new Random(run).shuffle(patterns)
      val bags0 = shuffled.groupBy(_.value(0)).values.toVector
      val bags = if (rank) bags0
      else bags0.map { bag =>
        val f = Datasets.removeBagFilter(bag)
        Datasets.applyFilter(f)(bag)
      }
      println(s"${bags.size} <- bags.size")

      Datasets.kfoldCV2(bags, ks, parallel = true) { (trbags, tsbags, fold, minSize) =>
        val seed = run * 100 + fold
        val tr = trbags.flatten.toVector
        val ts = tsbags.flatten.toVector
        lazy val (trf, binaf, zscof) = criaFiltro(tr, fold)
        lazy val tsf = aplicaFiltro(ts, fold, binaf, zscof)

        if (leas(tr).isEmpty) {
          //          //ELM
          //          val l = NinteraELM(seed)
          //          var m = l.batchBuild(trf).asInstanceOf[ELMModel]
          //          m = l.modelSelectionFull(m)
          //          val rankMedio = media(trf.toSeq map (p => p.targets))
          //          val twoSpears = tsf map { p =>
          //            try {
          //              val spear = new SpearmansCorrelation().correlation(m.output(p), p.targets)
          //              val spearMaj = new SpearmansCorrelation().correlation(rankMedio, p.targets)
          //              //                        val spearMaj = new SpearmansCorrelation().correlation(rankMedio.zipWithIndex.map(_._2.toDouble), p.nominalSplit)
          //              (spear, spearMaj)
          //            } catch {
          //              case x: Throwable => error("\n " + m.output(p).toList + "\n " + rankMedio.toList + "\n " + p.targets.toList + " \n" + x)
          //            }
          //          }
          //          val (spearELM, spearMaj) = twoSpears.unzip
          //          Vector(Stat.media_desvioPadrao(spearELM)._1, Stat.media_desvioPadrao(spearMaj)._1)


          //clus; seed tb serve pra situar run e fold durante paralelização
          val arqtr = s"/run/shm/tr$seed"
          val arqts = s"/run/shm/ts$seed"
          instances2file(tr, arqtr)
          instances2file(ts, arqts)
          val f = new FileWriter(s"/run/shm/clus$seed.s")
          f.write(clusSettings(patterns.head.nattributes, patterns.head.nclasses, seed, arqtr, arqts))
          f.close()

          Clus.main(Array(s"/run/shm/clus$seed"))

          //          def
          val rankMedio = media(tr.toSeq map (p => p.targets))
          val twoSpears = ts map { p =>
            val rank = Array(0d)
            try {
              val spear = 0d //new SpearmansCorrelation().correlation(rank, p.targets)
              val spearMaj = 0d //new SpearmansCorrelation().correlation(rankMedio, p.targets)
              //                        val spearMaj = new SpearmansCorrelation().correlation(rankMedio.zipWithIndex.map(_._2.toDouble), p.nominalSplit)
              (spear, spearMaj)
            } catch {
              case x: Throwable => error("\n " + rank.toList + "\n " + rankMedio.toList + "\n " + p.nominalSplit.toList + " \n" + x)
            }
          }
          val (spearELM, spearMaj) = twoSpears.unzip
          Vector(Stat.media_desvioPadrao(spearELM)._1, Stat.media_desvioPadrao(spearMaj)._1)

        } else {
          //weka
          leas(tr) flatMap { le =>
            println(s"${le.limpa} <- le.limpa")
            val (trtestbags, tstestbags, m) = if (le.querFiltro) (trf.groupBy(x => x.vector), tsf.groupBy(x => x.vector), le.build(trf))
            else (tr.groupBy(x => x.vector), ts.groupBy(x => x.vector), le.build(tr))
            Seq(trtestbags, tstestbags) map (bags => (bags.map(_._2) map { tsbag =>
              tsbag.map(_.label).contains(m.predict(tsbag.head))
            }).count(_ == true) / bags.size.toDouble)
          }
        }
      }
    }
  }
}
/*

active-learning-scala: Active Learning library for Scala
Copyright (c) 2014 Davi Pereira dos Santos

   This program is free software: you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation, either version 3 of the License, or
   (at your option) any later version.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

package clean.tex

import java.io.{File, FileWriter}

import clean.lib.{Log, Rank, FilterTrait}
import clus.Clus
import ml.Pattern
import ml.classifiers.{NinteraELM, Learner}
import ml.models.ELMModel
import org.apache.commons.math3.stat.correlation.SpearmansCorrelation
import util.{Stat, Datasets}
import weka.core.converters.ArffSaver
import weka.filters.Filter
import weka.filters.unsupervised.attribute.ReplaceMissingValues

import scala.util.Random

trait MetaTrait extends FilterTrait with Rank with Log {
  def clusSettings(natts: Int, targets: Int, seed: Int, arqtr: String, arqts: String) = {
    val ultimoDesc = natts + 1
    val primeiroTarget = ultimoDesc + 1
    val ultimoTarget = primeiroTarget + targets - 1
    Seq(
      "[Data]",
      s"File = $arqtr.arff",
      s"TestSet = $arqts.arff",
      "",
      "[General]",
      s"RandomSeed = $seed",
      "",
      "[Attributes]",
      s"Descriptive = 2-$ultimoDesc",
      s"Target = $primeiroTarget-$ultimoTarget",
      s"Clustering = $primeiroTarget-$ultimoTarget",
      "Weights = 1",
      "",
      "[Tree]",
      "Heuristic = VarianceReduction",
      "FTest = 1",
      "PruningMethod = M5Multi",
      "M5PruningMult = 1",
      "",
      "[Output]",
      "WritePredictions = {Test}"
    ).mkString("\n")
  }


  def arff(strats: String, exemplos: Seq[(Seq[(String, String, String)], String)], print: Boolean = false, context: String, rank: Boolean) = {
    lazy val labels = exemplos.map(x => x._2).distinct.sorted
    lazy val classAtt = "@attribute class {" + labels.map(x => "\"" + x + "\"").mkString(",") + "}"
    val attsNameType = exemplos.head._1 map { case (no, va, ty) => s"$no $ty" }
    val header = List(s"@relation autogeneratedby$context") ++ (attsNameType map (nt => s"@attribute $nt")) ++ (if (rank) List() else List(classAtt))
    val data = exemplos.map(x => "\"" + x._1.head._2 + "\"," + x._1.tail.map(_._2).mkString(",") + (if (rank) "" else s"," + "\"" + x._2 + "\""))
    if (print) {
      //      println("labels: " + labels.mkString(" "))
      //      println(s"#classes: ${labels.size}")
      println(s"#atributos: ${exemplos.head._1.size}")
      println(s"#exemplos: ${exemplos.size}")
    }
    Seq("%" + strats) ++ header ++ Seq("@data") ++ data
  }

  def grava(arq: String, linhas: Seq[String], print: Boolean = false): Unit = {
    val fw = new FileWriter(arq)
    linhas foreach (x => fw.write(s"$x\n"))
    fw.close()
    if (print) linhas foreach println
  }

  def instances2file(patterns: Vector[Pattern], arq: String) {
    val as = new ArffSaver()
    as.setInstances(Datasets.patterns2instances(patterns))
    as.setFile(new File(arq + ".arff"))
    as.writeBatch()
  }

  def cv(patterns: Vector[Pattern], leas: Vector[Pattern] => Vector[Learner], rank: Boolean, rs: Int, ks: Int) = {
    (1 to rs) map { run =>
      val shuffled = new Random(run).shuffle(patterns)
      val bags0 = shuffled.groupBy(_.value(0)).values.toVector
      val bags = if (rank) bags0
      else bags0.map { bag =>
        val f = Datasets.removeBagFilter(bag)
        Datasets.applyFilter(f)(bag)
      }
      println(s"${bags.size} <- bags.size")

      Datasets.kfoldCV2(bags, ks, parallel = !true) { (trbags, tsbags, fold, minSize) =>
        val seed = run * 100 + fold
        val tr = trbags.flatten.toVector
        val ts = tsbags.flatten.toVector
        lazy val (trf, tsf) = criaFiltroReplaceMissing(tr, ts)

        if (leas(tr).isEmpty) {
          //ELM
          val l = NinteraELM(seed)
          var m = l.batchBuild(trf).asInstanceOf[ELMModel]
          m = l.modelSelectionFull(m)
          val ELMRanks = tsf.toVector map { p => m.output(p) }

          //clus; seed tb serve pra situar run e fold durante paralelização
          val arqtr = s"/run/shm/tr$seed"
          val arqts = s"/run/shm/ts$seed"
          instances2file(tr, arqtr)
          instances2file(ts, arqts)
          val f = new FileWriter(s"/run/shm/clus$seed.s")
          f.write(clusSettings(patterns.head.nattributes, patterns.head.nclasses, seed, arqtr, arqts))
          f.close()
          Clus.main(Array(s"/run/shm/clus$seed"))
          val clusPredictionsARFF = Datasets.arff(s"/run/shm/clus$seed.test.pred.arff", dedup = false) match {
            case Right(x) => x
            case Left(m) => error(s"${m} <- m")
          }

          val clusOrigRanks_clusPrunRanks = Vector("Original-p", "Pruned-p") map { str =>
            clusPredictionsARFF.map { pa =>
              pa.array.zipWithIndex.flatMap { case (v, i) => if (pa.attribute(i).name.startsWith(str)) Some(v) else None }
            }
          }
          val tstargets = ts.toSeq map (_.targets)
          val rankMedio = media(tstargets)
          val defaultRanks = ts map (_ => rankMedio)

          clusOrigRanks_clusPrunRanks ++ Vector(ELMRanks, defaultRanks) flatMap { ranks =>
            val spears = ranks.zip(tstargets) map { case (ranking, targets) =>
              try {
                new SpearmansCorrelation().correlation(ranking, targets)
              } catch {
                case x: Throwable => error("\n " + ranking.toList + "\n " + rankMedio.toList + "\n " + targets.toList + " \n" + x)
              }
            }
            Seq(0d, Stat.media_desvioPadrao(spears)._1)
          }

        } else {
          //weka
          leas(tr) flatMap { le =>
            println(s"${le.limpa} <- le.limpa")
            val (trtestbags, tstestbags, m) = if (le.querFiltro) (trf.groupBy(x => x.vector), tsf.groupBy(x => x.vector), le.build(trf))
            else (tr.groupBy(x => x.vector), ts.groupBy(x => x.vector), le.build(tr))
            Seq(trtestbags, tstestbags) map (bags => (bags.map(_._2) map { tsbag =>
              tsbag.map(_.label).contains(m.predict(tsbag.head))
            }).count(_ == true) / bags.size.toDouble)
          }
        }
      }
    }
  }
}